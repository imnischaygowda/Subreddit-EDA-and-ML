{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nisch\\anaconda3\\envs\\peoject_2_subreddit\\lib\\site-packages\\requests\\__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# '''\n",
    "# Author: Nischay Gowda nischaygowda105@gmail.com\n",
    "# Date: 2023-02-08 12:17:30\n",
    "# LastEditors: Nischay Gowda nischaygowda105@gmail.com\n",
    "# LastEditTime: 2023-02-08 12:23:11\n",
    "# '''\n",
    "\n",
    "# PRAW package\n",
    "import requests\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from pmaw import PushshiftAPI\n",
    "import sqlalchemy\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import requests\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "\n",
    "import datetime, time\n",
    "# importing timezone from pytz module\n",
    "from pytz import timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fetch data using reddit url.\n",
    "def get_subreddit_data(SUBREDDIT, LIMIT, TIMEFRAME):\n",
    "    # without Authemticator\n",
    "    # try:\n",
    "    #     api = PushshiftAPI()\n",
    "    #     post_data = api.submission(subreddit = SUBREDDIT)\n",
    "    # except:\n",
    "    #     print('An Error Occured')\n",
    "    # return post_data\n",
    "    api = PushshiftAPI()\n",
    "    post_data = api.search_submissions(subreddit = SUBREDDIT,limit = LIMIT, listing = 'top')\n",
    "    post_list = [post for post in post_data]\n",
    "    return post_list\n",
    "\n",
    "def get_data_in_dataframe(r_data):\n",
    "    \n",
    "    # create a dataframe\n",
    "    data_dict = defaultdict()\n",
    "    \n",
    "    for r_post in r_data:\n",
    "        \n",
    "        # Data points available for a reddit post.\n",
    "        # ['approved_at_utc', 'subreddit', 'selftext', 'author_fullname', 'saved', 'mod_reason_title', 'gilded', 'clicked', 'title', \n",
    "        # 'link_flair_richtext', 'subreddit_name_prefixed', 'hidden', 'pwls', 'link_flair_css_class', 'downs', 'top_awarded_type', \n",
    "        # 'hide_score', 'name', 'quarantine', 'link_flair_text_color', 'upvote_ratio', 'author_flair_background_color', 'subreddit_type', \n",
    "        # 'ups', 'total_awards_received', 'media_embed', 'author_flair_template_id', 'is_original_content', 'user_reports', 'secure_media', \n",
    "        # 'is_reddit_media_domain', 'is_meta', 'category', 'secure_media_embed', 'link_flair_text', 'can_mod_post', 'score', 'approved_by', \n",
    "        # 'is_created_from_ads_ui', 'author_premium', 'thumbnail', 'edited', 'author_flair_css_class', 'author_flair_richtext', 'gildings', \n",
    "        # 'content_categories', 'is_self', 'mod_note', 'created', 'link_flair_type', 'wls', 'removed_by_category', 'banned_by', 'author_flair_type', \n",
    "        # 'domain', 'allow_live_comments', 'selftext_html', 'likes', 'suggested_sort', 'banned_at_utc', 'view_count', 'archived', 'no_follow', \n",
    "        # 'is_crosspostable', 'pinned', 'over_18', 'all_awardings', 'awarders', 'media_only', 'can_gild', 'spoiler', 'locked', 'author_flair_text', \n",
    "        # 'treatment_tags', 'visited', 'removed_by', 'num_reports', 'distinguished', 'subreddit_id', 'author_is_blocked', 'mod_reason_by', 'removal_reason', \n",
    "        # 'link_flair_background_color', 'id', 'is_robot_indexable', 'report_reasons', 'author', 'discussion_type', 'num_comments', 'send_replies', 'whitelist_status', \n",
    "        # 'contest_mode', 'mod_reports', 'author_patreon_flair', 'author_flair_text_color', 'permalink', 'parent_whitelist_status', 'stickied', 'url', 'subreddit_subscribers', \n",
    "        # 'created_utc', 'num_crossposts', 'media', 'is_video']\n",
    "        \n",
    "        data_dict[r_post['id']] = {'id':r_post['id'],'created_date_utc':r_post['created_utc'],'subreddit_id':r_post['subreddit_id'],\n",
    "                                   'title':r_post['title'],'body':r_post['selftext'], 'url':r_post['url'],'score':r_post['score'],'comments':r_post['num_comments']}\n",
    "    \n",
    "    main_df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "    return main_df\n",
    "    \n",
    "# def get_post_titles(r):\n",
    "#     '''\n",
    "#     Get a List of post titles\n",
    "#     '''\n",
    "#     posts = []\n",
    "#     for post in r['data']['children']:\n",
    "#         for val in post['data']:\n",
    "#             posts.append(val)\n",
    "#     return posts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened DB successful\n"
     ]
    }
   ],
   "source": [
    "# input parameters.\n",
    "SUBREDDIT = 'askreddit'\n",
    "LIMIT = 1000\n",
    "TIMEFRAME = 'all'\n",
    "LISTING = 'top'\n",
    "\n",
    "# database\n",
    "DATABASE_LOCATION = \"sqlite:///subreddit_data.sqlite\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    r = get_subreddit_data(SUBREDDIT, LIMIT, TIMEFRAME)\n",
    "    # print(r)\n",
    "    \n",
    "    main_data = get_data_in_dataframe(r)\n",
    "    # print(main_data)\n",
    "    # print(main_data.info())\n",
    "    \n",
    "    \n",
    "    # giving the format of datetime\n",
    "    format = \"%Y-%m-%d\"\n",
    "\n",
    "    main_data['created_date'] = ''\n",
    "    # convert float UTC to Date.\n",
    "    for i in range(len(main_data)):\n",
    "        main_data['created_date'][i] = datetime.datetime.fromtimestamp(main_data['created_date_utc'][i]).strftime(format)\n",
    "    main_data.reset_index(inplace=True)\n",
    "    main_data = main_data[['id','created_date_utc', 'created_date', 'subreddit_id', 'title', 'body', 'url','score', 'comments']]\n",
    "    # print(main_data.size)\n",
    "    \n",
    "    # Loading to database\n",
    "    engine = sqlalchemy.create_engine(DATABASE_LOCATION)\n",
    "    conn = sqlite3.connect('subreddit_data.sqlite')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # SQL query to create subreddit data.\n",
    "    sql_query = ''' \n",
    "                CREATE TABLE IF NOT EXISTS subreddit_data(\n",
    "                    ID VARCHAR(200),\n",
    "                    CREATED_DATE_UTC VARCHAR(200),\n",
    "                    CREATED_DATE VARCHAR(200),\n",
    "                    SUBREDDIT_ID VARCHAR(200),\n",
    "                    POST_TITLE VARCHAR(200),\n",
    "                    POST_BODY VARCHAR(200),\n",
    "                    POST_URL VARCHAR(200),\n",
    "                    POST_KARMA INTEGER, \n",
    "                    POST_COMMENTS VARCHAR(200)                \n",
    "                )\n",
    "                '''\n",
    "                \n",
    "    cursor.execute(sql_query)\n",
    "    print('Opened DB successful')\n",
    "    \n",
    "    try:\n",
    "        main_data.to_sql('subreddit_data', engine, index = False, if_exists = 'replace')\n",
    "    except:\n",
    "        print('Data alredy exists')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peoject_2_subreddit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1d2e16babf7a0670260ab185b9bba551e6e5605eea3db5455568b60ff7ec34f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
